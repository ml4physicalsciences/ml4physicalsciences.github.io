<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-48900508-9"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-48900508-9');
		</script>

		<title>Machine Learning and the Physical Sciences, NeurIPS 2022</title>
		<meta name="description" content="Website for the Machine Learning and the Physical Sciences (MLPS) workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS)">
		<meta name="author" content="Atilim Gunes Baydin">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<link rel="stylesheet" href="assets/css/lightbox.css" />
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<!-- <span class="logo"><img src="images/logo.svg" alt="" /></span> -->
						<img style="width:5em;"src="images/NeurIPS-logo-white.svg" alt="" />
						<h1>Machine Learning and the Physical Sciences</h1>
						<p>Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS)<br>
						December 3, 2022</p>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#about">About</a></li>
					    	<!-- <li><a href="#schedule">Schedule</a></li>  -->
							<li><a href="#papers">Papers</a></li> 
							<li><a href="#speakers">Speakers</a></li>
							<!-- <li><a href="#cfp">Call for papers</a></li> -->
							<li><a href="#organizers">Organizers</a></li>
							<li><a href="#sponsors">Sponsors</a></li>
							<li>
								<div class="dropdown">
								  <a>All Years</a>
								  <div class="dropdown-content">
										<a href="https://ml4physicalsciences.github.io/2022">2022</a>
										<a href="https://ml4physicalsciences.github.io/2021">2021</a>
										<a href="https://ml4physicalsciences.github.io/2020">2020</a>
										<a href="https://ml4physicalsciences.github.io/2019">2019</a>
								    	<a href="https://ml4physicalsciences.github.io/2017">2017</a>
								  </div>
								</div>
							</li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<section id="about" class="main">
							<div class="spotlight">
								<div class="content">
									<header class="major">
										<h2>About</h2>
									</header>

									<h3>Important dates</h3>
									<ul>
										<li>Submission Deadline: <strike>September 22</strike> September 29, 2022, 23:59 <a href="https://www.timeanddate.com/time/zones/aoe">AoE</a></li>
										<li>Review Deadline: <strike>October 8</strike> October 14, 2022, 23:59 <a href="https://www.timeanddate.com/time/zones/aoe">AoE</a></li>
										<li>Author (accept/reject) notification: <strike>October 15</strike> October 20, 2022, 23:59 <a href="https://www.timeanddate.com/time/zones/aoe">AoE</a></li>
										<li>Camera-ready (final) paper deadline: November 19, 2022, 23:59 <a href="https://www.timeanddate.com/time/zones/aoe">AoE</a></li>
										<li>Poster deadline: November 19, 2022, 23:59 <a href="https://www.timeanddate.com/time/zones/aoe">AoE</a></li>
										<li>Workshop: December 3, 2022</li>
									</ul>

									<p>
									The <strong>Machine Learning and the Physical Sciences</strong> workshop aims to provide an informal, inclusive and leading-edge venue for research and discussions at the interface of machine learning (ML) and the physical sciences. This interface spans (1) applications of ML in physical sciences (<emph>ML for physics</emph>), (2) developments in ML motivated by physical insights (<emph>physics for ML</emph>), and most recently (3) convergence of ML and physical sciences (<emph>physics with ML</emph>) which inspires questioning what scientific understanding means in the age of complex-AI powered science, and what roles machine and human scientists will play in developing scientific understanding in the future.
									</p>

									<p>Recent years have seen a tremendous increase in cases where ML models are used for scientific processing and discovery, and similarly, instances where tools and insights from the physical sciences are brought to the study of ML models. The harmonious co-development of the two fields is not a surprise: ML methods have had great success in learning complex representations of data that enable novel modeling and data processing approaches in many scientific disciplines. Indeed, in some sense, ML and physics are concerned with a shared goal of characterizing the true probability distributions of nature. As ML and physical science research becomes more intertwined, questions naturally arise around what scientific understanding is when science is performed with the assistance of complex and highly parameterized models. Taken to the extreme, if an ML model is developed for a scientific task and demonstrates robustness and generalizability but lacks interpretability in terms of an existing scientific knowledge basis, is this still a useful scientific result?</p>
									
									<p>The breadth of work at the intersection of ML and physical sciences is answering many important questions for both fields while opening up new ones that can only be addressed by a joint effort of both communities. By bringing together ML researchers and physical scientists who apply and study ML, we expect to strengthen the much needed interdisciplinary dialogue, introduce exciting new open problems to the broader community, and stimulate the production of new approaches to solving challenging open problems in the sciences. Invited talks from leading individuals in both communities will cover the state-of-the-art techniques and set the stage for this workshop, which will also include contributed talks selected from submissions. The workshop will also feature an expert panel discussion on "Philosophy of Science in the AI Era" --- focusing on topics such as scientific understanding in the age of extremely complex ML models, automating science via machines, and ML models as source of inspiration for scientific discoveries. Finally, there will be multiple community building activities such as a voluntary mentorship opportunity and round table discussions on curated topics to foster connection building and facilitate knowledge sharing across disciplines, backgrounds, and career stages.</p>

									<h2>NeurIPS 2022</h2>
									<p><span class="image left"><img style="width:6em;padding-left:0.5em;padding-top:.7em;" src="images/NeurIPS-logo.svg" alt="" /></span>The Machine Learning and the Physical Sciences 2022 workshop will be held on December 3, 2022 at the New Orleans Convention Center in New Orleans, USA as a part of the <a href="https://neurips.cc/">36th annual conference on Neural Information Processing Systems</a> (NeurIPS). The workshop is planned to take place in a hybrid format inclusive of virtual participation.
								</div>
							</div>
						</section>

						<section id="papers" class="main">
							<div class="spotlight">
								<div class="content">
									<header class="major">
										<h2>Papers</h2>
									</header>

									<table>
										<tbody>
											<tr>
												<td>2</td>
												<td>Deformation Theory of Boltzmann Distributions<br>Mate, Balint A*; Fleuret, François</td>
												</tr>
												<tr>
												<td>4</td>
												<td>Leveraging the Stochastic Predictions of Bayesian Neural Networks for Fluid Simulations<br>Mueller, Maximilian*; Greif, Robin; Jenko, Frank; Thuerey, Nils</td>
												</tr>
												<tr>
												<td>5</td>
												<td>Characterizing information loss in a chaotic double pendulum with the Information Bottleneck<br>Murphy, Kieran A*; Bassett, Danielle S</td>
												</tr>
												<tr>
												<td>6</td>
												<td>Discovering Long-period Exoplanets using Deep Learning with Citizen Science Labels<br>Malik, Shreshth A*; Eisner, Nora; Lintott, Chris; Gal, Yarin</td>
												</tr>
												<tr>
												<td>8</td>
												<td>HIGlow: Conditional Normalizing Flows for High-Fidelity HI Map Modeling<br>Friedman, Roy*; Hassan, Sultan SH</td>
												</tr>
												<tr>
												<td>10</td>
												<td>Molecular Fingerprints for Robust and Efficient ML-Driven Molecular Generation<br>Tazhigulov, Ruslan N.*; Schiller, Joshua; Oppenheim, Jacob; Winston, Max</td>
												</tr>
												<tr>
												<td>11</td>
												<td>Detecting structured signals in radio telescope data using RKHS<br>Tsuchida, Russell*; Yong, Suk Yee</td>
												</tr>
												<tr>
												<td>12</td>
												<td>Training physical networks like neural networks: deep physical neural networks<br>Wright, Logan*; Onodera, Tatsuhiro; Stein, Martin; Wang, Tianyu; Schachter, Darren; Hu, Zoey; McMahon, Peter</td>
												</tr>
												<tr>
												<td>13</td>
												<td>Virgo: Scalable Unsupervised Classification of Cosmological Shock Waves<br>Lamparth, Max*; Böss, Ludwig; Steinwandel, Ulrich; Dolag, Klaus</td>
												</tr>
												<tr>
												<td>15</td>
												<td>Learning Feynman Diagrams using Graph Neural Networks<br>Norcliffe, Alexander LI*; Mitchell, Harrison; Lió, Pietro</td>
												</tr>
												<tr>
												<td>16</td>
												<td>Certified data-driven physics-informed greedy auto-encoder simulator<br>He, Xiaolong*; Choi, Youngsoo; Fries, William; Belof, Jonathan; Chen, Jiun-Shyan</td>
												</tr>
												<tr>
												<td>17</td>
												<td>Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs<br>Kohl, Georg*; Chen, Liwei; Thuerey, Nils</td>
												</tr>
												<tr>
												<td>18</td>
												<td>Physics-Informed Machine Learning of Dynamical Systems for Efficient Bayesian Inference<br>Dhulipala, Som*; Che, Yifeng; Shields, Michael</td>
												</tr>
												<tr>
												<td>19</td>
												<td>Offline Model-Based Reinforcement Learning for Tokamak Control<br>Char, Ian*; Abbate, Joseph; Bardoczi, Laszlo; Boyer, Mark; Chung, Youngseog; Conlin, Rory; Erickson, Keith; Mehta, Viraj; Richner, Nathan; Kolemen, Egemen; Schneider, Jeff</td>
												</tr>
												<tr>
												<td>20</td>
												<td>Physics-Driven Convolutional Autoencoder Approach for CFD Data Compressions<br>Olmo, Alberto*; Zamzam, Ahmed S; Glaws, Andrew; King, Ryan</td>
												</tr>
												<tr>
												<td>21</td>
												<td>Decay-aware neural network for event classification in collider physics<br>Kishimoto, Tomoe*; Morinaga, Masahiro; Saito, Masahiko; Tanaka, Junichi</td>
												</tr>
												<tr>
												<td>22</td>
												<td>Learning Electron Bunch Distribution along a FEL Beamline by Normalising Flows<br>Willmann, Anna*; Couperus Cabadağ, Jurjen Pieter; Chang, Yen-Yu; Pausch, Richard; Ghaith, Amin; Debus, Alexander; Irman, Arie; Bussmann, Michael; Schramm, Ulrich; Hoffmann, Nico</td>
												</tr>
												<tr>
												<td>23</td>
												<td>Improving Generalization with Physical Equations<br>Wehenkel, Antoine*; Behrmann, Jens; Hsu, Hsiang; Sapiro, Guillermo; Louppe, Gilles; Jacobsen, Joern-Henrik</td>
												</tr>
												<tr>
												<td>25</td>
												<td>Phase transitions and structure formation in learning local rules<br>Zunkovic, Bojan*; Ilievski, Enej</td>
												</tr>
												<tr>
												<td>26</td>
												<td>Lyapunov Regularized Forecaster<br>Zheng, Rong*; Yu, Rose</td>
												</tr>
												<tr>
												<td>27</td>
												<td>Ad-hoc Pulse Shape Simulation using Cyclic Positional U-Net<br>Li, Aobo*</td>
												</tr>
												<tr>
												<td>28</td>
												<td>Generating astronomical spectra from photometry with conditional diffusion models<br>Doorenbos, Lars*; Cavuoti, Stefano; Longo, Giuseppe; Brescia, Massimo; Sznitman, Raphael; Márquez Neila, Pablo</td>
												</tr>
												<tr>
												<td>29</td>
												<td>Learning Uncertainties the Frequentist Way: Calibration and Correlation in High Energy Physics<br>Gambhir, Rikab*; Thaler, Jesse; Nachman, Benjamin</td>
												</tr>
												<tr>
												<td>30</td>
												<td>Machine Learning for Chemical Reactions \\A Dance of Datasets and Models<br>Schreiner, Mathias*; Bhowmik, Arghya; Vegge, Tejs; Busk, Jonas; Jørgensen, Peter B; Winther, Ole</td>
												</tr>
												<tr>
												<td>31</td>
												<td>ML4LM: Machine Learning for Safely Landing on Mars<br>Wu, David D*; Chung, Wai Tong; Ihme, Matthias</td>
												</tr>
												<tr>
												<td>33</td>
												<td>A Self-Supervised Approach to Reconstruction in Sparse X-Ray Computed Tomography<br>Mendoza, Rey; Nguyen, Minh; Weng Zhu, Judith; Perciano, Talita; Dumont, Vincent; Mueller, Juliane; Ganapati, Vidya*</td>
												</tr>
												<tr>
												<td>35</td>
												<td>Semi-Supervised Domain Adaptation for Cross-Survey Galaxy Morphology Classification and Anomaly Detection<br>Ciprijanovic, Aleksandra*; Lewis, Ashia; Pedro, Kevin; Madireddy, Sandeep; Nord, Brian; Perdue, Gabriel Nathan; Wild, Stefan</td>
												</tr>
												<tr>
												<td>37</td>
												<td>Flexible learning of quantum states with generative query neural networks<br>Zhu, Yan; Wu, Ya-Dong*; Bai, Ge; Wang, Dong-Sheng; Wang, Yuexuan; Chiribella, Giulio</td>
												</tr>
												<tr>
												<td>38</td>
												<td>Transfer Learning with Physics-Informed Neural Networks for Efficient Simulation of Branched Flows<br>Pellegrin, Raphael PF*; Bullwinkel, Jeffrey B; Mattheakis, Marios; Protopapas, Pavlos</td>
												</tr>
												<tr>
												<td>40</td>
												<td>Decorrelation with conditional normalizing flows<br>Klein, Samuel*; Golling, Tobias</td>
												</tr>
												<tr>
												<td>41</td>
												<td>A New Task: Deriving Semantic Class Targets for the Physical Sciences<br>Bowles, Micah R*</td>
												</tr>
												<tr>
												<td>43</td>
												<td>Machine-learned climate model corrections from a global storm-resolving model<br>Kwa, Anna*</td>
												</tr>
												<tr>
												<td>44</td>
												<td>Amortized Bayesian Inference for Supernovae in the Era of the Vera Rubin Observatory Using Normalizing Flows<br>Villar, Victoria A*</td>
												</tr>
												<tr>
												<td>45</td>
												<td>Scalable Bayesian Inference for Finding Strong Gravitational Lenses<br>Patel, Yash P*; Regier, Jeffrey</td>
												</tr>
												<tr>
												<td>48</td>
												<td>D-optimal neural exploration of nonlinear physical systems<br>Blanke, Matthieu*; Lelarge, Marc</td>
												</tr>
												<tr>
												<td>49</td>
												<td>A Trust Crisis In Simulation-Based Inference? Your Posterior Approximations Can Be Unfaithful<br>Hermans, Joeri; Delaunoy, Arnaud*; Rozet, François; Wehenkel, Antoine; Begy, Volodimir; Louppe, Gilles</td>
												</tr>
												<tr>
												<td>50</td>
												<td>Towards Creating Benchmark Datasets of Universal Neural Network Potential for Material Discovery<br>Takamoto, So*; Shinagawa, Chikashi; Charoenphakdee, Nontawat</td>
												</tr>
												<tr>
												<td>51</td>
												<td>Applications of Differentiable Physics Simulations in Particle Accelerator Modeling<br>Roussel, Ryan*; Edelen, Auralee</td>
												</tr>
												<tr>
												<td>52</td>
												<td>A Curriculum-Training-Based Strategy for Distributing Collocation Points during Physics-Informed Neural Network Training<br>Münzer, Marcus*; Bard, Christopher</td>
												</tr>
												<tr>
												<td>53</td>
												<td>Machine learning for complete intersection Calabi-Yau manifolds<br>Erbin, Harold*; Tamaazousti, Mohamed; Finotello, Riccardo</td>
												</tr>
												<tr>
												<td>55</td>
												<td>Learning latent variable evolution for the functional renormalization group<br>Medvidović, Matija*; Toschi, Alessandro; Sangiovanni, Giorgio; Franchini, Cesare; Millis, Andy; Sengupta, Anirvan; Di Sante, Domenico</td>
												</tr>
												<tr>
												<td>57</td>
												<td>Renormalization in the neural network-quantum field theory correspondence<br>Erbin, Harold*; Lahoche, Vincent; Ousmane Samary, Dine</td>
												</tr>
												<tr>
												<td>59</td>
												<td>Neuro-Symbolic Partial Differential Equation Solver<br>Akbari Mistani, Pouria*; Pakravan, Samira; Ilango, Rajesh; Choudhry, Sanjay; Gibou, Frederic</td>
												</tr>
												<tr>
												<td>60</td>
												<td>Data-driven discovery of non-Newtonian astronomy via learning non-Euclidean Hamiltonian<br>So, Oswin*; Li, Gongjie; Theodorou, Evangelos; Tao, Molei</td>
												</tr>
												<tr>
												<td>62</td>
												<td>Normalizing Flows for Hierarchical Bayesian Analysis: A Gravitational Wave Population Study<br>Ruhe, David*; Wong, Kaze; Cranmer, Miles; Forré, Patrick</td>
												</tr>
												<tr>
												<td>63</td>
												<td>Identifying AGN host galaxies with convolutional neural networks<br>Guo, Ziting*; Wu, John; Sharon, Chelsea</td>
												</tr>
												<tr>
												<td>64</td>
												<td>Efficiently Moving Instead of Reweighting Collider Events with Machine Learning<br>Mastandrea, Radha*; Nachman, Benjamin</td>
												</tr>
												<tr>
												<td>65</td>
												<td>SuNeRF: Validation of a 3D Global Reconstruction of the Solar Corona Using Simulated EUV Images<br>Bintsi, Kyriaki-Margarita*; Jarolim, Robert; Tremblay, Benoit; Santos, Miraflor P; Jungbluth, Anna; Mason, James; Sundaresan, Sairam; Vourlidas, Angelos; Downs, Cooper; Caplan, Ronald; Muñoz-Jaramillo, Andrés</td>
												</tr>
												<tr>
												<td>66</td>
												<td>Validation Diagnostics for SBI algorithms based on Normalizing Flows<br>Linhart, Julia*; Gramfort, Alexandre ; Rodrigues, Pedro</td>
												</tr>
												<tr>
												<td>67</td>
												<td>Differentiable composition for model discovery<br>Rochma Sharabi, Omer*; Louppe, Gilles</td>
												</tr>
												<tr>
												<td>68</td>
												<td>Fast kinematics modeling for conjunction with lens image modeling<br>Gomer, Matthew R*; Biggio, Luca; Ertl, Sebastian; Wang, Han; Galan, Aymeric; Van de Vyvere, Lyne; Sluse, Dominique; Vernardos, Georgios; Suyu, Sherry</td>
												</tr>
												<tr>
												<td>69</td>
												<td>Generating Calorimeter Showers as Point Clouds<br>Schnake, Simon Patrik*; Krücker, Dirk; Borras, Kerstin</td>
												</tr>
												<tr>
												<td>70</td>
												<td>Combinational-convolution  for flow-based sampling algorithm<br>Tomiya, Akio*</td>
												</tr>
												<tr>
												<td>72</td>
												<td>Applying Deep Reinforcement Learning to The HP Model For Protein Structure Prediction<br>Yang, Kaiyuan*; Huang, Houjing; Vandans, Olafs; Murali, Adithyavairavan; Tian, Fujia; Yap, Roland H.C.; Dai, Liang</td>
												</tr>
												<tr>
												<td>73</td>
												<td>Physics solutions for privacy leaks in machine learning<br>Pozas-Kerstjens, Alejandro*; Hernandez-Santana, Senaida; Pareja Monturiol, Jose Ramon; Castrillon Lopez, Marco; Scarpa, Giannicola; Gonzalez-Guillen, Carlos E.; Perez-Garcia, David</td>
												</tr>
												<tr>
												<td>74</td>
												<td>Thermophysical Change Detection on the Moon with the Lunar Reconnaissance Orbiter Diviner sensor<br>Delgado-Centeno, Jose  Ignacio*; Bucci, Silvia; Liang, Ziyi; Gaffinet, Ben; Bickel, Valentin T; Moseley, Ben; Olivares, Miguel</td>
												</tr>
												<tr>
												<td>75</td>
												<td>From Particles to Fluids: Dimensionality Reduction for Non-Maxwellian Plasma Velocity Distributions Validated in the Fluid Context<br>da Silva, Daniel E*</td>
												</tr>
												<tr>
												<td>76</td>
												<td>Simplifying Polylogarithms with Machine Learning<br>Dersy, Aurelien*; Schwartz, Matthew; Zhang, Xiaoyuan</td>
												</tr>
												<tr>
												<td>78</td>
												<td>NLP Inspired Training Mechanics For Modeling Transient Dynamics<br>Ghule, Lalit J*; Ranade, Rishikesh; Pathak, Jay</td>
												</tr>
												<tr>
												<td>79</td>
												<td>Neural Network-based Real-Time Parameter Estimation in Electrochemical Sensors with Unknown Confounding Factors<br>Jariwala, Sarthak*</td>
												</tr>
												<tr>
												<td>81</td>
												<td>Deep Learning Modeling of Subgrid Physics in Cosmological N-body Simulations<br>Chatziloizos, George-Mark; Lanusse, François; Cazenave, Tristan*</td>
												</tr>
												<tr>
												<td>82</td>
												<td>Monte Carlo Techniques for Addressing Large Errors and Missing Data in Simulation-based Inference<br>Wang, Bingjie*; Leja, Joel; Villar, Victoria A; Speagle, Joshua</td>
												</tr>
												<tr>
												<td>83</td>
												<td>Learning dynamical systems: an example from open quantum system dynamics.<br>Novelli, Pietro*</td>
												</tr>
												<tr>
												<td>84</td>
												<td>Reducing Down(stream)time: Pretraining Molecular GNNs using Heterogeneous AI Accelerators<br>Bilbrey, Jenna A*; Herman, Kristina; Sprueill, Henry; Xantheas, Sotiris; Das, Payel; Lopez Roldan, Manuel; Kraus, Mike; Helal, Hatem; Choudhury, Sutanay</td>
												</tr>
												<tr>
												<td>85</td>
												<td>Why are deep learning-based models of geophysical turbulence long-term unstable?<br>Chattopadhyay, Ashesh K*; Hassanzadeh, Pedram </td>
												</tr>
												<tr>
												<td>87</td>
												<td>Wavelets Beat Monkeys at Adversarial Robustness<br>Su, Jingtong*; Kempe, Julia</td>
												</tr>
												<tr>
												<td>88</td>
												<td>Emulating Fast Processes in Climate Models<br>Brenowitz, Noah D*; Perkins, W. Andre; Nugent, Jacqueline M.; Watt-Meyer, Oliver; Clark, Spencer K.; Kwa, Anna; Henn, Brian; McGibbon, Jeremy; Bretherton, Christopher S.</td>
												</tr>
												<tr>
												<td>90</td>
												<td>GAUCHE: A Library for Gaussian Processes in Chemistry<br>Griffiths, Ryan-Rhys*; Klarner, Leo; Moss, Henry B; Ravuri, Aditya; Truong, Sang; Rankovic, Bojana; Du, Yuanqi; Jamasb, Arian R.; Schwartz, Julius; Tripp, Austin J; Kell, Gregory; Bourached, Anthony; Chan, Alex J; Moss, Jacob; Guo, Chengzhi; Lee, Alpha; Schwaller, Philippe; Tang, Jian</td>
												</tr>
												<tr>
												<td>91</td>
												<td>One-shot learning for solution operators of partial differential equations<br>Lu, Lu*; Jiao, Anran; Pathak, Jay; Ranade, Rishikesh; He, Haiyang</td>
												</tr>
												<tr>
												<td>92</td>
												<td>Qubit seriation: Undoing data shuffling using  spectral ordering<br>Acharya, Atithi*; Rudolph, Manuel; Chen, Jing; Miller, Jacob; Perdemo-Ortiz, Alejandro</td>
												</tr>
												<tr>
												<td>93</td>
												<td>Differentiable Physics-based Greenhouse Simulation<br>Nguyen, Nhat M.*; Tran, Hieu; Duong, Minh; Bui, Hanh; Tran, Kenneth</td>
												</tr>
												<tr>
												<td>94</td>
												<td>First principles physics-informed neural network for   quantum wavefunctions and eigenvalue  surfaces<br>Mattheakis, Marios*; Schleder, Gabriel R.; Larson, Daniel; Kaxiras, Efthimios</td>
												</tr>
												<tr>
												<td>95</td>
												<td>Clustering Behaviour of Physics-Informed Neural Networks: Inverse Modeling of An Idealized Ice Shelf<br>Iwasaki, Yunona*; Lai, Ching-Yao</td>
												</tr>
												<tr>
												<td>96</td>
												<td>Adversarial Noise Injection for Learned Turbulence Simulations<br>Su, Jingtong*; Kempe, Julia; Fielding, Drummond; Tsilivis, Nikolaos; Cranmer, Miles; Ho, Shirley</td>
												</tr>
												<tr>
												<td>97</td>
												<td>Do Better QM9 Models Extrapolate as Better Quantum Chemical Property Predictors?<br>ZHANG, YUCHENG*; Charoenphakdee, Nontawat; Takamoto, So</td>
												</tr>
												<tr>
												<td>99</td>
												<td>HubbardNet: Efficient Predictions of the Bose-Hubbard Model Spectrum with Deep Neural Networks<br>Zhu , Ziyan*; Mattheakis, Marios; Pan, Weiwei; Kaxiras, Efthimios</td>
												</tr>
												<tr>
												<td>100</td>
												<td>Intra-Event Aware Imitation Game for Fast Detector Simulation<br>Hashemi, Hosein*; Hartmann, Nikolai; Sharifzadeh, Sahand; Kahn, James; Kuhr, Thomas</td>
												</tr>
												<tr>
												<td>108</td>
												<td>Point Cloud Generation using Transformer Encoders and Normalising Flows<br>Käch, Benno*; Krücker, Dirk; Melzer, Isabell</td>
												</tr>
												<tr>
												<td>109</td>
												<td>Galaxy Morphological Classification with Deformable Attention Transformer<br>Kang, Seok-Un; Shin, Min-su; Kim, Taehwan*</td>
												</tr>
												<tr>
												<td>110</td>
												<td>Stabilization and Acceleration of CFD Simulation by Controlling Relaxation Factor Based on Residues: An SNN Based Approach<br>Dey, Sounak*; Banerjee, Dighanchal; Maurya, Mithilesh; Ahmad, Dilshad</td>
												</tr>
												<tr>
												<td>111</td>
												<td>Simulation-based inference of the 2D ex-situ stellar mass fraction distribution of galaxies using variational autoencoders<br>Angeloudi, Eirini*; Huertas-Company, Marc; Falcón-Barroso, Jesús; Sarmiento, Regina; Walo-Martín, Daniel; Pillepich, Annalisa; Vega Ferrero, Jesús</td>
												</tr>
												<tr>
												<td>112</td>
												<td>Uncertainty quantification methods for ML-based surrogate models of scientific applications<br>Basu, Kishore; Hao, Judy; Hintz, Delphine ; Shah, Dev; Palmer, Aaron; Hora, Gurpreet Singh; Nwankwo, Darian; White, Laurent*</td>
												</tr>
												<tr>
												<td>113</td>
												<td>Contrasting random and learned features in deep Bayesian linear regression<br>Zavatone-Veth, Jacob A*; Tong, William; Pehlevan, Cengiz</td>
												</tr>
												<tr>
												<td>114</td>
												<td>DS-GPS : A Deep Statistical Graph Poisson Solver (for faster CFD simulations)<br>Nastorg, Matthieu*</td>
												</tr>
												<tr>
												<td>115</td>
												<td>Dynamical Mean Field Theory of Kernel Evolution in Wide Neural Networks<br>Bordelon, Blake A; Pehlevan, Cengiz*</td>
												</tr>
												<tr>
												<td>118</td>
												<td>A Neural Network Subgrid Model of the Early Stages of Planet Formation<br>Pfeil, Thomas*; Cranmer, Miles; Ho, Shirley; Armitage, Philip; Birnstiel, Tilman; Klahr, Hubert</td>
												</tr>
												<tr>
												<td>121</td>
												<td>One Network to Approximate Them All: Amortized Variational Inference of Ising Ground States<br>Sanokowski, Sebastian*; Berghammer, Wilhelm; Kofler, Johannes; Hochreiter, Sepp; Lehner, Sebastian</td>
												</tr>
												<tr>
												<td>122</td>
												<td>Hybrid integration of the gravitational N-body problem with Artificial Neural Networks<br>Saz Ulibarrena, Veronica*</td>
												</tr>
												<tr>
												<td>123</td>
												<td>Neural Fields for Fast and Scalable Interpolation of Geophysical Ocean Variables<br>Johnson, Juan Emmanuel*; Lguensat, Redouane; fablet, ronan; Cosme, Emmanuel; Le Sommer, Julien</td>
												</tr>
												<tr>
												<td>124</td>
												<td>CAPE: Channel-Attention-Based PDE Parameter Embeddings for SciML<br>Takamoto, Makoto*; Alesiani, Francesco; Niepert, Mathias</td>
												</tr>
												<tr>
												<td>125</td>
												<td>Real-time Health Monitoring of Heat Exchangers using Hypernetworks and PINNs<br>Majumdar, Ritam; Jadhav, Vishal; Deodhar, Anirudh; Karande, Shirish; Vig, Lovekesh; Runkana, Venkataramana*</td>
												</tr>
												<tr>
												<td>128</td>
												<td>Physics-Informed CNNs for Super-Resolution of Sparse Observations on Dynamical Systems<br>Kelshaw, Daniel J*; Rigas, Georgios; Magri, Luca</td>
												</tr>
												<tr>
												<td>129</td>
												<td>Neural Inference of Gaussian Processes for Time Series Data of Quasars<br>Danilov, Egor*; Ciprijanovic, Aleksandra; Nord, Brian</td>
												</tr>
												<tr>
												<td>130</td>
												<td>Predicting Full-Field Turbulent Flows Using Fourier Neural Operator<br>Renn, Peter I*; Lale, Sahin; Wang, Cong; Li, Zongyi; Anandkumar, Animashree; Gharib, Morteza</td>
												</tr>
												<tr>
												<td>131</td>
												<td>Deep Learning-Based Spatiotemporal Multi-Event Reconstruction for Delay-Line Detectors<br>Knipfer, Marco*; Gleyzer, Sergei; Meier, Stefan; Heimerl, Jonas; Hommelhoff, Peter</td>
												</tr>
												<tr>
												<td>133</td>
												<td>Tensor networks for active inference with discrete observation spaces<br>Wauthier, Samuel T*; Vanhecke, Bram; Verbelen, Tim; Dhoedt, Bart</td>
												</tr>
												<tr>
												<td>134</td>
												<td>Generative Design of Material Microstructures for Organic Solar Cells using Diffusion Models<br>Herron, Ethan*; Lee, Xian Yeow; Balu, Aditya; Ganapathysubramanian, Baskar  ; Sarkar, Soumik; Krishnamurthy, Adarsh</td>
												</tr>
												<tr>
												<td>135</td>
												<td>Skip Connections for High Precision Regressors<br>Paul, Ayan*; Bishara, Fady; Dy, Jennifer</td>
												</tr>
												<tr>
												<td>137</td>
												<td>Employing CycleGANs to Generate Realistic STEM Images for Machine Learning<br>Khan, Abid A*; Lee, Chia-Hao; Pinshane, Huang; Clark, Bryan</td>
												</tr>
												<tr>
												<td>138</td>
												<td>Strong-Lensing Source Reconstruction with Denoising Diffusion Restoration Models<br>Karchev, Kosio*; Anau Montel, Noemi; Coogan, Adam; Weniger, Christoph</td>
												</tr>
												<tr>
												<td>139</td>
												<td>Score-based Seismic Inverse Problems<br>Ravula, Sriram*; Voytan, Dimitri P; Liebman, Elad; Tuvi, Ram; Gandhi, Yash; Ghani, Hamza H ; Ardel, Alexandre; Sen, Mrinal; Dimakis, Alex</td>
												</tr>
												<tr>
												<td>140</td>
												<td>Deep-pretrained-FWI: combining supervised learning with physics-informed neural network<br>MULLER, ANA PAULA OLIVEIRA*; Bom , Clecio Roque; Costa, Jessé Carvalho; Faria, Elisângela Lopes ; de Albuquerque, Marcelo Portes ; de Albuquerque, Marcio Portes </td>
												</tr>
												<tr>
												<td>142</td>
												<td>Interpretable Encoding of Galaxy Spectra<br>Liang, Yan*; Melchior, Peter M; Lu, Sicong</td>
												</tr>
												<tr>
												<td>143</td>
												<td>HyperFNO: Improving the Generalization Behavior of  Fourier Neural Operators<br>Alesiani, Francesco*; Takamoto, Makoto; Niepert, Mathias</td>
												</tr>
												<tr>
												<td>144</td>
												<td>Adaptive Selection of Atomic Fingerprints for High-Dimensional Neural Network Potentials<br>Sandberg, Johannes E*; Devijver, Emilie; Jakse, Noel; Voigtmann, Thomas</td>
												</tr>
												<tr>
												<td>146</td>
												<td>Neural Network Prior Mean for Particle Accelerator Injector Tuning<br>Xu, Connie *; Roussel, Ryan; Edelen, Auralee</td>
												</tr>
												<tr>
												<td>147</td>
												<td>Detection is truncation: studying source populations with truncated marginal neural ratio estimation<br>Anau Montel, Noemi*; Weniger, Christoph</td>
												</tr>
												<tr>
												<td>148</td>
												<td>De-noising non-Gaussian fields in cosmology with normalizing flows<br>Rouhiainen, Adam*; Münchmeyer, Mortiz</td>
												</tr>
												<tr>
												<td>149</td>
												<td>Finding NEEMo: Geometric Fitting using Neural Estimation of the Energy Mover’s Distance<br>Kitouni, Ouail*; Williams, Mike; Nolte, Niklas</td>
												</tr>
												<tr>
												<td>150</td>
												<td>A robust estimator of mutual information for deep learning interpretability<br>Piras, Davide*; Peris, Hiranya ; Pontzen, Andrew; Lucie-Smith, Luisa; Nord, Brian; Guo, Ningyuan (Lillian)</td>
												</tr>
												<tr>
												<td>152</td>
												<td>DIGS: Deep Inference of Galaxy Spectra with Neural Posterior Estimation<br>Khullar, Gourav*; Nord, Brian; Ciprijanovic, Aleksandra; Poh, Jason; Xu, Fei; Samudre, Ashwin</td>
												</tr>
												<tr>
												<td>153</td>
												<td>Strong Lensing Parameter Estimation on Ground-Based Imaging Data Using Simulation-Based Inference<br>Poh, Jason*; Samudre, Ashwin; Ciprijanovic, Aleksandra; Nord, Brian; Frieman, Joshua; Khullar, Gourav</td>
												</tr>
												<tr>
												<td>154</td>
												<td>Closing the resolution gap in Lyman alpha simulations with deep learning<br>Jacobus, Cooper H*; Harrington, Peter ; Lukić,  Zarija</td>
												</tr>
												<tr>
												<td>155</td>
												<td>Physics-Informed Convolutional Neural Networks for Corruption Removal on Dynamical Systems<br>Kelshaw, Daniel J*; Magri, Luca</td>
												</tr>
												<tr>
												<td>156</td>
												<td>Do graph neural networks learn jet substructure?<br>Mokhtar, Farouk*; Kansal, Raghav; Duarte, Javier</td>
												</tr>
												<tr>
												<td>158</td>
												<td>Multi-Fidelity Transfer Learning for accurate database PDE approximation<br>Liu, Wenzhuo*; Yagoubi, Mouadh; Schoenauer, Marc; Danan, David</td>
												</tr>
												<tr>
												<td>159</td>
												<td>Source Identification and Field Reconstruction of Advection-Diffusion Process from Sparse Sensor Measurements<br>Daw, Arka*; Yeo, Kyongmin; Karpatne, Anuj; Klein, Levente</td>
												</tr>
												<tr>
												<td>160</td>
												<td>Energy based models for tomography of quantum spin-lattice systems<br>J., Abhijith*; Vuffray, Marc D; Lokhov, Andrey</td>
												</tr>
												<tr>
												<td>161</td>
												<td>Geometry-aware Autoregressive Models for Calorimeter Shower Simulations<br>Liu, Junze*; Ghosh, Aishik; Smith, Dylan; Baldi, Pierre; Whiteson, Daniel</td>
												</tr>
												<tr>
												<td>162</td>
												<td>Diversity Balancing Generative Adversarial Networks for fast simulation of the Zero Degree Calorimeter in the ALICE experiment at CERN<br>Dubiński, Jan Michał *; Deja, Kamil; Wenzel, Sandro; Rokita, Przemysław; Trzcinski, Tomasz</td>
												</tr>
												<tr>
												<td>163</td>
												<td>Statistical Inference for Coadded Astronomical Images<br>Wang, Mallory; Mendoza, Ismael*; Regier, Jeffrey; Avestruz, Camille; Wang, Cheng</td>
												</tr>
												<tr>
												<td>166</td>
												<td>Domain Adaptation for Simulation-Based Dark Matter Searches with Strong Gravitational Lensing<br>Kumbam, Pranath Reddy; Gleyzer, Sergei; Toomey, Michael W*; Tidball, Marcos</td>
												</tr>
												<tr>
												<td>167</td>
												<td>A hybrid Reduced Basis and Machine-Learning algorithm for building Surrogate Models: a first application to electromagnetism<br>Ribes, Alejandro*; Persicot, Ruben; Meyer, Lucas T; Ducreux, Jean-Pierre</td>
												</tr>
												<tr>
												<td>168</td>
												<td>Control and Calibration of GlueX Central Drift Chamber Using Gaussian Process Regression<br>McSpadden, Diana*; Jeske, Torri; Jarvis, Naomi; Lawrence, David; Britton, Thomas; Kalra, Nikhil</td>
												</tr>
												<tr>
												<td>169</td>
												<td>Graph Structure from Point Clouds: Geometric Attention is All You Need<br>Murnane, Daniel*</td>
												</tr>
												<tr>
												<td>171</td>
												<td>Deconvolving Detector Effects for Distribution Moments<br>Desai, Krish*; Nachman, Benjamin; Thaler, Jesse</td>
												</tr>
												<tr>
												<td>173</td>
												<td>Multi-scale Digital Twin: Developing a fast and physics-infused surrogate model for groundwater contamination with uncertain climate models<br>Wang, Lijing*; Kurihana, Takuya; Meray, Aurelien; Mastilovic, Ilijana; Praveen, Satyarth; Xu, Zexuan; Memarzadeh, Milad; Lavin, Alexander; Wainwright, Haruko</td>
												</tr>
												<tr>
												<td>174</td>
												<td>Normalizing Flows for Fragmentation and Hadronization<br>Youssef, Ahmed*; Ilten, Phil; Menzo, Tony; Zupan, Jure; Szewc, Manuel; Mrenna, Stephen; Wilkinson, Michael K.</td>
												</tr>
												<tr>
												<td>175</td>
												<td>Topological Jet Tagging<br>Thomas, Dawson S*; Demers, Sarah; Krishnaswamy, Smita; Rieck, Bastian A</td>
												</tr>
												<tr>
												<td>176</td>
												<td>Atmospheric retrievals of exoplanets using learned parameterizations of pressure-temperature profiles<br>Gebhard, Timothy D*; Angerhausen, Daniel; Konrad, Björn; Alei, Eleonora; Quanz, Sascha; Schölkopf, Bernhard</td>
												</tr>
												<tr>
												<td>177</td>
												<td>Recovering Galaxy Cluster Convergence from Lensed CMB with Generative Adversarial Networks<br>Parker, Liam H*; Han, Dongwon; Ho, Shirley; Lemos, Pablo</td>
												</tr>
												<tr>
												<td>178</td>
												<td>DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking<br>Corso, Gabriele*; Stärk, Hannes; Jing, Bowen; Barzilay, Dr.Regina; Jaakkola, Tommi</td>
												</tr>
												<tr>
												<td>180</td>
												<td>Addressing out-of-distribution data for flow-based gravitational wave inference<br>Maximillian, Dax*; Green, Stephen R; Wildberger, Jonas Bernhard; Gair, Jonathan; Puerrer, Michael; Macke, Jakob; Buonanno, Alessandra; Schölkopf, Bernhard</td>
												</tr>
												<tr>
												<td>182</td>
												<td>Plausible Adversarial Attacks on Direct Parameter Inference Models in Astrophysics<br>Horowitz, Benjamin A*; Melchior, Peter M</td>
												</tr>
												<tr>
												<td>183</td>
												<td>Astronomical Image Coaddition with Bundle-Adjusting Radiance Fields<br>Hutton, Harlan*; Palegar, Harshitha; Ho, Shirley; Cranmer, Miles; Melchior, Peter M; Eubank, Jenna</td>
												</tr>
												<tr>
												<td>184</td>
												<td>Amortized Bayesian Inference of GISAXS Data with Normalizing Flows<br>Zhdanov, Maksim*; Randolph, Lisa; Kluge, Thomas; Nakatsutsumi, Motoaki; Gutt, Christian; Ganeva, Marina; Hoffmann, Nico</td>
												</tr>
												<tr>
												<td>186</td>
												<td>GAN-Flow: A dimension-reduced variational framework for physics-based inverse problems<br>Dasgupta, Agnimitra*; Patel, Dhruv; Ray, Deep; Johnson, Erik; Oberai, Assad</td>
												</tr>
												<tr>
												<td>187</td>
												<td>Computing the Bayes-optimal classifier and exact maximum likelihood estimator with a semi-realistic generative model for jet physics<br>Cranmer, Kyle; Drnevich, Matthew*; Greenspan, Lauren; Macaluso, Sebastian; Pappadopulo, Duccio</td>
												</tr>
												<tr>
												<td>188</td>
												<td>Emulating cosmological growth functions with B-Splines<br>Kwan, Ngai Pok*; Modi, Chirag; Li, Yin; Ho, Shirley</td>
												</tr>
												<tr>
												<td>189</td>
												<td>ClimFormer - a Spherical Transformer model for long-term climate projections<br>Ruhling Cachay, Salva; Mitra, Peetak P*; Kim, Sookyung; Hazarika, Subhashis; Hirasawa, Haruki; Hingmire, Dipti S; Singh, Hansi; Ramea, Kalai</td>
												</tr>
												<tr>
												<td>191</td>
												<td>The Senseiver: attention-based global field reconstruction from sparse observations<br>Santos, Javier E*; Fox, Zachary; Mohan, Arvind T; Viswanathan, Hari S; Lubbers, NIcholas</td>
												</tr>
												<tr>
												<td>192</td>
												<td>SE(3)-equivariant self-attention via invariant features<br>Chen, Nan*; Villar, Soledad</td>
												</tr>
												<tr>
												<td>193</td>
												<td>Can denoising diffusion probabilistic models generate realistic astrophysical fields?<br>Mudur, Nayantara*;  Finkbeiner, Douglas </td>
												</tr>
												<tr>
												<td>194</td>
												<td>Likelihood-Free Frequentist Inference for Calorimetric Muon Energy Measurement in High-Energy Physics<br>Masserano, Luca*; Lee, Ann; Izbicki, Rafael; Kuusela, Mikael; Dorigo, Tommaso</td>
												</tr>
												<tr>
												<td>195</td>
												<td>Improved Training of Physics-informed Neural Networks using Energy-Based priors: A Study on Electrical Impedance Tomography<br>Pokkunuru, Akarsh*; Rooshenas, Pedram; Strauss, Thilo; Abhishek, Anuj; Khan, Taufiquar R</td>
												</tr>
												<tr>
												<td>196</td>
												<td>Uncertainty Aware Deep Learning for Particle Accelerators<br>Rajput, Kishansingh*; Schram, Malachi; Somayaji, Karthik</td>
												</tr>
												<tr>
												<td>197</td>
												<td>Graphical Models are All You Need: Per-interaction reconstruction uncertainties in a dark matter detection experiment<br>Peters, Christina*; Higuera, Aaron; Liang, Shixiao; Bajwa, Waheed; Tunnell, Christopher</td>
												</tr>
												<tr>
												<td>198</td>
												<td>PELICAN: Permutation Equivariant and Lorentz Invariant or Covariant Aggregator Network for Particle Physics<br>Offermann, Jan*; Bogatskiy, Alexander; Hoffman, Timothy; Miller, David</td>
												</tr>
												<tr>
												<td>199</td>
												<td>FO-PINNs: A First-Order formulation for Physics~Informed Neural Networks<br>Gladstone, Rini Jasmine*; Nabian, Mohammad Amin; Meidani, Hadi</td>
												</tr>
												<tr>
												<td>200</td>
												<td>Learning the nonlinear manifold of extreme aerodynamics<br>Fukami, Kai*; Taira, Kunihiko</td>
												</tr>
												<tr>
												<td>201</td>
												<td>Geometric NeuralPDE (GNPnet) Models for Learning Dynamics<br>Fasina, Oluwadamilola Fasina*; Krishnaswamy, Smita; Krishnapriyan, Aditi</td>
												</tr>
												<tr>
												<td>203</td>
												<td>PIPS: Path Integral Stochastic Optimal Control for Path Sampling in Molecular Dynamics<br>Holdijk, Lars*; Du, Yuanqi; Hooft, Ferry; Jaini, Priyank; Ensing, Bernd; Welling, Max</td>
												</tr>
												<tr>
												<td>204</td>
												<td>Anomaly Detection with Multiple Reference Datasets in High Energy Physics<br>Chen, Mayee*; Nachman, Benjamin; Sala, Frederic</td>
												</tr>
												<tr>
												<td>206</td>
												<td>Towards a non-Gaussian Generative Model of large-scale Reionization Maps<br>Lin, Yu-Heng*; Hassan, Sultan SH; Régaldo-Saint Blancard, Bruno; Eickenberg, Michael; Modi, Chirag</td>
												</tr>
												<tr>
												<td>207</td>
												<td>Elements of effective machine learning datasets in astronomy<br>Boscoe, Bernadette*; Do , Tuan</td>
												</tr>
												<tr>
												<td>211</td>
												<td>Shining light on data<br>Kumar, Akshat*; Sarovar, Mohan</td>
												</tr>
												<tr>
												<td>212</td>
												<td>A Novel Automatic Mixed Precision Approach For Physics Informed Training<br>Xue, Jinze; Subramaniam, Akshay*; Hoemmen, Mark</td>
												</tr>
												<tr>
												<td>213</td>
												<td>Probabilistic Mixture Modeling For End-Member Extraction in Hyperspectral Data<br>Hoidn, Oliver*; Mishra, Aashwin; Mehta, Apurva</td>
												</tr>
												<tr>
												<td>214</td>
												<td>Posterior samples of source galaxies in strong gravitational lenses with score-based priors<br>Adam, Alexandre*; Coogan, Adam; Malkin, Nikolay; Legin, Ronan; Perreault-Levasseur, Laurence; Hezaveh, Yashar; Bengio, Yoshua</td>
												</tr>
												<tr>
												<td>215</td>
												<td>Learning Integrable Dynamics with Action-Angle Networks<br>Daigavane, Ameya*; Kosmala, Arthur; Cranmer, Miles; Smidt, Tess; Ho, Shirley</td>
												</tr>
												<tr>
												<td>216</td>
												<td>Particle-level Compression for New Physics Searches<br>Huang, Yifeng*; Collins, Jack; Nachman, Benjamin; Knapen, Simon; Whiteson, Daniel</td>
												</tr>
												<tr>
												<td>217</td>
												<td>Inferring molecular complexity from mass spectrometry data using machine learning<br>Gebhard, Timothy D*; Bell, Aaron; Gong, Jian; Hastings, Jaden J. A.; Fricke, George M; Cabrol, Nathalie; Sandford, Scott; Phillips, Michael; Warren-Rhodes, Kimberley; Baydin, Atilim Gunes</td>
												</tr>
												<tr>
												<td>218</td>
												<td>CaloMan: Fast generation of calorimeter showers with density estimation on learned manifolds<br>Cresswell, Jesse*; Ross, Brendan L; Loaiza-Ganem, Gabriel; Reyes-Gonzalez, Humberto; Letizia, Marco; Caterini, Anthony</td>
												</tr>
												<tr>
												<td>220</td>
												<td>Physics-informed Bayesian Optimization of an Electron Microscope<br>Ma, Desheng*</td>
												</tr>
												<tr>
												<td>224</td>
												<td>One-Class Dense Networks for Anomaly Detection<br>Karr, Norman*; Nachman, Benjamin; Shih, David</td>
												</tr>
												<tr>
												<td>225</td>
												<td>Self-supervised detection of atmospheric phenomena from remotely sensed synthetic aperture radar imagery<br>Glaser, Yannik*; Sadowski, Peter; Stopa, Justin</td>
												</tr>
												<tr>
												<td>227</td>
												<td>Emulating cosmological multifields with generative adversarial networks<br>Andrianomena, Sambatra HS*; Hassan, Sultan; Villaescusa-Navarro, Francisco</td>
												</tr>
												<tr>
												<td>228</td>
												<td>Physics-informed neural networks for modeling rate- and temperature-dependent plasticity<br>Arora, Rajat; Kakkar, Pratik; Amit, Chakraborty; Dey, Biswadip*</td>
												</tr>
												<tr>
												<td>229</td>
												<td>A probabilistic deep learning model to distinguish cusps and cores in dwarf galaxies<br>Expósito, Julen*; Huertas-Company, Marc; Di Cintio, Arianna; Brook, Chris; Macciò, Andrea; Grant, Rob; Arjona, Elena</td>
												</tr>
												<tr>
												<td>230</td>
												<td>Learning-based solutions to nonlinear hyperbolic PDEs: Empirical insights on generalization errors<br>Thonnam Thodi, Bilal*; Ambadipudi, Sai Venkata Ramana; Jabari, Saif Eddin</td>
												</tr>
												<tr>
												<td>232</td>
												<td>Modeling halo and central galaxy orientations on the SO(3) manifold with score-based generative models<br>Jagvaral, Yesukhei*; Lanusse, Francois; Mandelbaum, Rachel</td>
												</tr>
												<tr>
												<td>233</td>
												<td>Geometric path augmentation for inference  of sparsely observed stochastic nonlinear systems<br>Maoutsa, Dimitra*</td>
												</tr>
												<tr>
												<td>234</td>
												<td>How good is the Standard Model? Machine learning multivariate Goodness of Fit tests<br>Grosso, Gaia*; Letizia, Marco; Wulzer, Andrea; Pierini, Maurizio</td>
												</tr>
												<tr>
												<td>235</td>
												<td>Score Matching via Differentiable Physics<br>Holzschuh, Benjamin J*; Vegetti, Simona ; Thuerey, Nils</td>
												</tr>
												<tr>
												<td>237</td>
												<td>Super-resolving Dark Matter Halos using Generative Deep Learning<br>Schaurecker, David*</td>
												</tr>
												<tr>
												<td>238</td>
												<td>Using Shadows to Learning Ground State Properties of Quantum Hamiltonians<br>Tran, Viet T.*; Lewis, Laura; Kofler, Johannes; Huang, Hsin-Yuan; Kueng, Richard; Hochreiter, Sepp; Lehner, Sebastian</td>
												</tr>
												<tr>
												<td>239</td>
												<td>Set-Conditional Set Generation for Particle Physics<br>Ganguly, Sanmay; Heinrich, Lukas*; Kakati, Nilotpal; Soybelman, Nathalie</td>
												</tr>
												<tr>
												<td>240</td>
												<td>Cosmology from Galaxy Redshift Surveys with PointNet<br>Anagnostidis, Sotirios-Konstantinos*; Thomsen, Arne; Refregier, Alexandre; Kacprzak, Tomasz; Biggio, Luca; Hofmann, Thomas; Troester, Tilman</td>
												</tr>
												<tr>
												<td>241</td>
												<td>Finding active galactic nuclei through Fink<br>Russeil, Etienne Sédick*; Ishida, Emille; Peloton, Julien; Moller, Anais; Le Montagner, Roman</td>
												</tr>
												<tr>
												<td>242</td>
												<td>HGPflow: Particle reconstruction as hyperedge prediction<br>Dreyer, Etienne*; Kakati, Nilotpal; Armando Di Bello, Francesco</td>
												</tr>
												<tr>
												<td>243</td>
												<td>Continual learning autoencoder training for a particle-in-cell simulations via streaming<br>Stiller, Patrick*; Makdani, Varun; Pöschel, Franz; Pausch, Richard; Debus, Alexander; Bussmann, Michael; Hoffmann, Nico</td>
												</tr>
												<tr>
												<td>244</td>
												<td>On Using Deep Learning Proxies as Forward Models in Optimization Problems<br>Albreiki, Fatima A*; Belayouni, Nidhal; Gupta, Deepak K</td>
												</tr>
												<tr>
												<td>245</td>
												<td>Time-aware Bayesian optimization for adaptive particle accelerator tuning<br>Kuklev, Nikita*; Sun, Yine; Shang, Hairong; Borland, Michael; Fystro, Gregory</td>
												</tr>
												<tr>
												<td>246</td>
												<td>Identifying Hamiltonian Manifold in Neural Networks<br>Song, Yeongwoo; Jeong, Hawoong*</td>
												</tr>
												<tr>
												<td>247</td>
												<td>Physics-Informed Neural Networks as Solvers for the Time-Dependent Schrödinger Equation<br>Shah, Karan*; Stiller, Patrick; Hoffmann, Nico; Cangi, Attila</td>
												</tr>
												<tr>
												<td>248</td>
												<td>A physics-informed search for metric solutions to Ricci flow, their embeddings, and visualisation<br>Jain, Aarjav*; Mishra, Challenger; Lió, Pietro</td>
												</tr>
												<tr>
												<td>250</td>
												<td>Physical models in machine learning imaging pipelines<br>Aversa, Marco*; Oala, Luis; Clausen, Christoph; Murray-Smith, Roderick; Sanguinetti, Bruno</td>
												</tr>
												<tr>
												<td>251</td>
												<td>Towards solving model bias in cosmic shear forward modeling<br>Remy, Benjamin*; Lanusse, Francois; Starck, Jean-Luc</td>
												</tr>
												<tr>
												<td>253</td>
												<td>Insight into cloud processes from unsupervised classification with a rotationally invariant autoencoder<br>Kurihana, Takuya*; Franke, James A; Foster, Ian; Wang, Ziwei; Moyer, Elisabeth</td>
												</tr>
												<tr>
												<td>254</td>
												<td>A fast and flexible machine learning approach to data quality monitoring<br>Letizia, Marco*; Grosso, Gaia; Wulzer, Andrea; Zanetti, Marco; Pazzini, Jacopo; Rando, Marco; Lai, Nicolò</td>
												</tr>
										</tbody>
									</table>
								</div>
							</div>
						</section>

						<section id="speakers" class="main">
							<div class="spotlight">
								<div class="content">
									<header class="major">
										<h2>Speakers and panelists</h2>
									</header>
									<h3>Invited talks</h3>
									<ul class="features">
									   <li>
										   <img style="width:9.1em; border-radius: 50%;" src="images/speaker_peiris.jpg" alt=""/>
										   <h3><a href="https://www.ucl.ac.uk/cosmoparticle/hiranya-peiris">Hiranya Peiris</a></br>UCL / Stockholm University</h3>
									   </li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/speaker_pfau.jpg" alt=""/>
											<h3><a href="http://davidpfau.com/">David Pfau</a></br>DeepMind</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/speaker_parisi.jpg" alt=""/>
											<h3><a href="https://chimera.roma1.infn.it/GIORGIO/index.html">Giorgio Parisi</a></br>Sapienza University of Rome</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/speaker_mikuni.jpg" alt=""/>
											<h3><a href="https://www.nersc.gov/about/nersc-staff/nesap-postdocs/vinicius-mikuni/">Vinicius Mikuni</a></br>LBNL / NERSC</h3>
										</li>	
										<li>
											<img style="width:9.1em; margin: 0.4em; border-radius: 50%;" src="images/speaker_nakalembe.jpg" alt=""/>
											<h3><a href="https://geog.umd.edu/facultyprofile/nakalembe/catherine/">Catherine Nakalembe</a></br>University of Maryland</h3>
										</li>	
										<li>
											<img style="width:9.1em; margin: 0.2em; border-radius: 50%;" src="images/speaker_kerner.jpg" alt=""/>
											<h3><a href="https://fullcircle.asu.edu/welcome/hannah-kerner/">Hannah Kerner</a></br>Arizona State University</h3>
										</li>	
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/speaker_felici.jpg" alt=""/>
											<h3><a href="https://people.epfl.ch/federico.felici">Federico Felici</a></br>EPFL</h3>
										</li>	
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/speaker_dogus.jpeg" alt=""/>
											<h3><a href="https://research.google/people/EkinDogusCubuk/">E. Doğuş Çubuk</a></br>Google Brain</h3>
										</li>	
									</ul>
									<h3>Panel discussion</h3>
									<ul class="features"> 
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/panel_krenn.png" alt=""/>
											<h3><a href="https://mariokrenn.wordpress.com/">Mario Krenn</a></br>MPI for the Science of Light</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/panel_sullivan.jpg" alt=""/>
											<h3><a href="https://www.eesullivan.com/">Emily Sullivan</a></br>Eindhoven U. of Technology</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/panel_kreel.jpg" alt=""/>
											<h3><a href="https://kathleenacreel.com/">Kathleen
												Creel</a></br>Northeastern University</h3>
										</li>
									</ul>
								</div>
							</div>
						</section>


						<section id="cfp" class="main">
							<div class="spotlight">
								<div class="content">
									<header class="major">
										<h2>Call for papers</h2>
									</header>

									<!-- <h3>Call for reviewers</h3>

									<p>We would appreciate your skills as a reviewer! Please consider applying for that role <a
											href="https://forms.gle/EELBnk7Z9ua3ygcZ9">here</a>.</p>

									<p><a href="https://forms.gle/EELBnk7Z9ua3ygcZ9" class="button">Sign up to review</a></p> -->

									<h3>Call for papers</h3>

									<p>In this workshop, we aim to bring together physical scientists and machine learning researchers who work at the intersection of these fields – i.e., applying machine learning to problems in the physical sciences (physics, chemistry, mathematics, astronomy, materials science, biophysics, and related sciences) or using physical insights to understand and improve machine learning techniques.</p>
									
									<p>We invite researchers to submit work particularly in the following areas or areas related to them:</p>

									<ul>
										<li><strong>ML for Physics:</strong> Applications of machine learning to physical sciences including astronomy, astrophysics, cosmology, biophysics, chemistry, climate science, earth science, materials science, mathematics, particle physics, or any related area;</li>
										<li><strong>Physics in ML:</strong> Strategies for incorporating prior scientific knowledge into machine learning algorithms, as well as applications of physical sciences to understand, model, and improve machine learning techniques;</li>
										<li><strong>ML in the scientific process:</strong> Machine learning model interpretability for obtaining insights to physical systems; Automating multiple elements of the scientific method for discovery and operations with experiments;</li>
										<li>Any other area related to the subject of the workshop, including but not limited to <strong>probabilistic methods</strong> that are relevant to physical systems, such as deep generative models, probabilistic programming, simulation-based inference, variational inference, causal inference, etc.</li>
									</ul>

									<p>We invite authors to follow the <a href="https://neurips.cc/Conferences/2022/PaperInformation/PaperChecklist">guidelines and best practices</a> from the NeurIPS conference.</p>

									<h4>Contributed Talks</h4>
									<p>Several accepted submissions will be selected for contributed talks. Contributed talks can be in-person or remote depending on the preference of the presenter.</p>

									<h4>Posters</h4>
									<p>Accepted work will be presented as posters during the workshop. At the same time as the in-person poster session, we will also facilitate a virtual poster session in GatherTown. Authors of submitted papers will be able to indicate their preference for an in-person presentation or a virtual presentation. Furthermore, in order to facilitate viewing presentations in  different time zones, the authors of each accepted paper will get the opportunity to submit a 5 minute video that summarizes their work. </p>
									<p>In case the number of posters that can be presented in-person is limited by the available physical space, a subset of works will be selected to be presented virtually. We will try to keep the authors preference for in-person/virtual poster presentations in mind during this selection. The remaining posters can be presented during the virtual poster session, and through the 5 minutes videos that will be uploaded to the workshop website.</p>
 
									<h4>Important note for work that will be/has been published elsewhere</h4>
									<p>All accepted works will be made available on the workshop website. This does not constitute an archival publication or formal proceedings; authors retain full copyright of their work and are free to publish their extended work in another journal or conference. We allow submission of works that overlap with papers that are under review or have been recently published in a conference or a journal, including physical science journals. However, we do not accept cross-submissions of the same content to multiple workshops at NeurIPS. (Check the <a href="https://blog.neurips.cc/2022/07/17/announcing-the-neurips-2022-workshops/">list of accepted workshops</a> this year.)</p>

									<h3>Submission instructions</h3>

									<p>Submit your work on the <a href="https://cmt3.research.microsoft.com/ML4PS2022">submission portal</a>.</p>

									<p><a href="https://cmt3.research.microsoft.com/ML4PS2022" class="button">Submit paper</a></p>

									<ul>
										<li>Submissions should be anonymized short papers (extended abstracts) up to 4 pages in PDF format, typeset using the <a href="https://neurips.cc/Conferences/2022/PaperInformation/StyleFiles">NeurIPS paper template</a>. </li>
										<li>The authors are required to include a short statement (approximately one paragraph) about the potential broader impact of their work, including any ethical aspects and future societal consequences, which may be positive or negative. The broader impact statement should come after the main paper content. The impact statement and references do not count towards the page limit. </li>
										<li>The NeurIPS style template includes a paper checklist intended to encourage best practices for responsible machine learning research (see <a href="https://neurips.cc/Conferences/2022/PaperInformation/PaperChecklist">associated guidelines</a>). Although we require authors to complete the checklist in order to raise awareness of and encourage these practices we expect, given the scope and format of the workshop, that many of the checklist items will not be applicable to the submitted papers. As such, answering "no" or "n/a" to the checklist items will not reflect adversely on submissions and we do not expect authors to further qualify their answers. </li>
										<li>Appendices are highly discouraged, and reviewers will not be required to read beyond the first 4 pages and the impact statement. </li>
										<li>A workshop-specific modified NeurIPS style file will be provided for the camera-ready versions, after the author notification date. </li>
										<li>Workshop organizers retain the right to reject submissions for editorial reasons: for example, any paper surpassing the page limitation or not including the broader impact statement will be desk-rejected. </li>
										<li>Submissions will be kept confidential until they are accepted and until authors confirm that they can be included in the workshop. If a submission is not accepted, or withdrawn for any reason, it will be kept confidential and not made public. </li>
									</ul>
									
									<h3>Review process</h3>

									<p>Submissions that follow the submission instructions correctly (i.e., are not rejected due to editorial reasons, such as exceeding the page limit,  missing the impact statement, etc,) are sent for peer-review. Below are some of the key points about this process that are shared with the reviewers and authors alike. Authors are expected to consider these in preparation of their submissions and when deciding to apply for the reviewer role.</p>

									<ul>
										<li>Papers are 4 pages long. Appendices are accepted but highly discouraged; the reviewers will not be required to read the appendices. </li>
										<li>There will be multiple reviewers for each paper.</li>
										<li>Reviewers will be able to state their confidence in their review.</li>
										<li>We will provide an easy-to-follow template for reviews so that both the pros and the cons of the submission can be highlighted.</li>
										<li>Reviewers will select their field of expertise so that each submission has reviewers from multiple fields. During the matching process, the same list of subject fields is used for submissions and reviewer expertise in order to maximize the quality of reviews.</li>
										<li>Potential conflicts of interest based on institution and author collaboration are addressed through the CMT review system.</li>
										<li>Criteria for a successful submission include: novelty, correctness, relevance to the field, at the intersection of ML and physical sciences, and showing promise for future impact. Negative or null results that add value and insight are welcome.</li>
										<li>There will be no rebuttal period. Minor flaws will not be the sole reason to reject a paper. Incomplete works at an advanced progress stage are welcome. </li>
									</ul>

									<h3>Instructions for accepted papers</h3>

									<p>Authors of accepted papers are expected to upload their camera-ready (final) paper and a poster by the deadlines given on this page. Optionally they can also record a short (5-minute) video describing their work.</p>
									
									<h4>Camera-ready paper</h4>

									<p>Please produce the "camera-ready" (final) version of your accepted paper by replacing the "neurips_2022.sty" style file with the "neurips_2022_ml4ps.sty" file <a href="https://ml4physicalsciences.github.io/2022/files/neurips_2022_ml4ps.sty">available here</a> and using the "final" package option (that is, "\usepackage[final]{neurips_2022_ml4ps}") to include author and affiliation information. The modified style file replaces the first-page footer to correctly refer to the workshop instead of the main conference. It is acceptable if your paper goes up to five pages (excluding acknowledgements, references, paper checklist, and any appendices if present) due to author and affiliation information taking extra space on the first page. The five-page limit is strict, and appendices are allowed but discouraged.</p>

									<p>Please revise your paper as much as possible to address reviewer comments reasonably. The revision would include minor corrections and/or changes directly addressing reviewer comments. Beyond these points, it is not acceptable to have any significant new material not present in your paper's reviewed version.
									Please upload the final PDF of your paper by the camera-ready deadline by logging in to the <a href="https://cmt3.research.microsoft.com/ML4PS2022">CMT website</a> (the same one used for the submissions) and using the camera-ready link shown with your existing submission.</p>
									
									<h4>Poster</h4>
									
									<p>Please upload your poster using the central NeurIPS <a href="https://neurips.cc/PosterUpload">poster upload page</a> and follow the instructions given there regarding the file formats and resolutions.
									To see the poster listed in the NeurIPS poster upload page, the co-author who is uploading the poster for a paper needs to be logged in to the <a href="https://neurips.cc/">neurips.cc</a> website using the same email address they used in their paper submission. If you encounter a problem regarding NeurIPS accounts (e.g., you have multiple accounts associated with different email addresses and you need to merge these accounts into a single one), please consult the <a href="https://neurips.cc/FAQ">NeurIPS account FAQs</a> and get in touch with the main NeurIPS conference organization who are handling accounts and registrations.</p>
									
									<p>The poster sessions will take place both in-person and virtually during the workshop. </p>
									<ul>
										<li>Physical presentation: You must come with your poster printed, preferrably on a lightweight paper of at most 24W x 36H inches. Your poster will be taped to the wall.</li>
										<li>Remote presentation: Virtual poster sessions will be held online at the same time as the physical poster sessions. Further instructions will be sent later.</li>
									</ul>
									
									<p>For the authors of contributed talks, posters are optional. </p>
									
									<h4>Optional video</h4>
									
									<p>You can record a short video in addition to your poster using a platform of your own choice (e.g., Youtube). Videos will be added to the workshop website, together with the papers and posters. The video should be a brief (less than 5 minutes) presentation of your work in the accepted paper. Uploading a video is optional. You should submit the URL of your presentation on CMT with the camera-ready version of your paper. </p>

								</div>
							</div>
						</section>

						<section id="organizers" class="main">
							<div class="spotlight">
								<div class="content">
									<header class="major">
										<h2>Organizers</h2>
									</header>

									<p>For questions and comments, please contact us at <a href="mailto:ml4ps2022@googlegroups.com">ml4ps2022@googlegroups.com</a>.</p>

									<ul class="features">
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/kucukbenli.jpg" alt=""/>
											<h3><a href="https://www.bu.edu/questrom/profile/emine-kucukbenli/">Emine Kucukbenli</a></br>Harvard University / Boston University</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/baydin.jpg" alt=""/>
											<h3><a href="http://www.robots.ox.ac.uk/~gunes/">Atılım Güneş Baydin</a></br>University of Oxford</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/dieng.jpg" alt=""/>
											<h3><a href="https://adjidieng.github.io/">Adji Bousso Dieng</a></br>Princeton University</h3>
										</li>
									</ul>
									<ul class="features">
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/louppe.jpg" alt=""/>
											<h3><a href="https://glouppe.github.io/">Gilles Louppe</a></br>University of Liège</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/thais.jpg" alt=""/>
											<h3><a href="https://www.linkedin.com/in/savannah-thais-12a7b95a/">Savannah Thais</a></br>Columbia University / IRIS-HEP</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/nord.jpg" alt=""/>
											<h3><a href="https://computing.fnal.gov/brian-nord/">Brian Nord</a></br>Fermilab</h3>
										</li>
									</ul>
									<ul class="features">
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/nachman.jpg" alt=""/>
											<h3><a href="https://bids.berkeley.edu/people/benjamin-nachman">Benjamin Nachman</a></br>Lawrence Berkeley National Laboratory</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/siddharth.jpg" alt=""/>
											<h3><a href="https://www.smsharma.io/">Siddharth Mishra-Sharma</a></br>MIT / Harvard / IAIFI</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/rianne.png" alt=""/>
											<h3><a href="https://www.microsoft.com/en-us/research/people/rvandenberg/">Rianne van den Berg</a></br>Microsoft Research, Amsterdam</h3>
										</li>
									</ul>
									<header class="major">
										<h2>Steering Committee</h2>
									</header>
									<ul class="features">
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/cranmer.jpg" alt=""/>
											<h3><a href="http://theoryandpractice.org/">Kyle Cranmer</a></br>University of Wisconsin / Meta AI</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/anandkumar.jpg" alt=""/>
											<h3><a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a></br>Caltech / NVIDIA</h3>
										</li>
										<li>
											<img style="width:9.1em; border-radius: 50%;" src="images/speaker_zdeborova.jpg" alt=""/>
											<h3><a href="https://www.epfl.ch/labs/spoc/prof-lenka-zdeborova/">Lenka Zdeborová</a></br>EPFL</h3>
										</li>
									</ul>
								</div>
							</div>
						</section>

						<section id="sponsors" class="main">
							<div class="spotlight">
								<div class="content">
									<header class="major">
										<h2>Sponsors</h2>
									</header>
									<ul class="features">
										<li style="margin: 0em 8em 2em 0em;">
											<h3><a style="text-decoration: none;color: #FFFFFF;" href="https://iopscience.iop.org/journal/2632-2153"><img style="width:125%;margin:0.5em 0em 0.5em 0em"src="images/mlst.jpg" alt="MLST" /></a></h3>
										</li>
									</ul>
									<p>Sponsors are welcome. Please contact <a href="mailto:ml4ps2022@googlegroups.com">us</a>.</p>
								</div>
							</div>
						</section>

						<section id="location" class="main">
							<div class="spotlight">
								<div class="content">
									<header class="major">
										<h2>Location</h2>
									</header>
									<p>NeurIPS 2022 will be a hybrid conference with physical and virtual participation. The physical component will take place at the
									<a href="https://mccno.com/">New Orleans Ernest N. Morial Convention Center</a>, 900 Convention Center Blvd, New Orleans, LA 70130, United States</p>
									<iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d27657.447675480584!2d-90.07160791540527!3d29.94547311541842!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x185d4d6c82fa192f!2sNew%20Orleans%20Ernest%20N.%20Morial%20Convention%20Center!5e0!3m2!1sen!2sus!4v1666014137915!5m2!1sen!2sus" width="100%" height="300em" frameborder="0" style="border:0" allowfullscreen></iframe>
								</div>
							</div>
						</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<h2>Contact</h2>
							<p>For questions and comments, please contact: <a href="mailto:ml4ps2022@googlegroups.com">ml4ps2022@googlegroups.com</a></p>
						</section>
						<!-- <p class="copyright">Background image: <a href="https://www.spacetelescope.org/images/potw1712a/">NGC 3447 from Hubble WFC3</a></p> -->
						<p class="copyright">Copyright &copy; Atılım Güneş Baydin. Design: <a href="https://html5up.net">HTML5 UP</a>.</br>Design inspired by <a href="http://bayesiandeeplearning.org/">http://bayesiandeeplearning.org/</a> by Yarin Gal.</p>
					</footer>

			</div>

		<!-- Scripts  -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>
			<!-- Default Statcounter code for
			ml4physicalsciences.github.io
			https://ml4physicalsciences.github.io/ -->
			<script type="text/javascript">
			var sc_project=12052169;
			var sc_invisible=1;
			var sc_security="0155c36a";
			var sc_https=1;
			</script>
			<script type="text/javascript"
			src="https://www.statcounter.com/counter/counter.js"
			async></script>
			<noscript><div class="statcounter"><a title="free hit
			counter" href="https://statcounter.com/"
			target="_blank"><img class="statcounter"
			src="https://c.statcounter.com/12052169/0/0155c36a/1/"
			alt="free hit counter"></a></div></noscript>
			<!-- End of Statcounter Code -->
			<script src="assets/js/lightbox.js"></script>
	</body>
</html>
